{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install addict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers\")\n",
    "process_dir = data_dir / \"processed\"\n",
    "log_dir = data_dir / \"demo/logs\"\n",
    "\n",
    "args = Dict({\n",
    "    \"batch_size\": 16,\n",
    "    \"run_name\": \"demo\", \n",
    "    \"epochs\": 200,\n",
    "    \"save_every\": 50,\n",
    "    \"loss_type\": \"dice\",\n",
    "    \"device\": \"cuda:0\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glacier_mapping.data.data import fetch_loaders\n",
    "from glacier_mapping.models.frame import Framework\n",
    "import glacier_mapping.train as tr\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from glacier_mapping.models.metrics import diceloss\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "\n",
    "conf = Dict(yaml.safe_load(open(\"conf/train.yaml\", \"r\")))\n",
    "train_folder = \"train\"\n",
    "dev_folder = \"dev\" \n",
    "print(process_dir / train_folder)\n",
    "print(process_dir / dev_folder)\n",
    "loaders = fetch_loaders(process_dir, args.batch_size, train_folder, dev_folder)\n",
    "device = torch.device(args.device)\n",
    "\n",
    "loss_fn = None\n",
    "outchannels = conf.model_opts.args.outchannels\n",
    "if args.loss_type == \"dice\":\n",
    "    loss_fn = diceloss(\n",
    "        act=torch.nn.Softmax(dim=1), \n",
    "        w=[0.6, 0.9, 0.2], # clean ice, debris, background\n",
    "        outchannels=outchannels, \n",
    "        label_smoothing=0.2\n",
    "    )\n",
    "    \n",
    "frame = Framework(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "# Setup logging\n",
    "writer = SummaryWriter(f\"{data_dir}/{args.run_name}/logs/\")\n",
    "writer.add_text(\"Arguments\", json.dumps(vars(args)))\n",
    "writer.add_text(\"Configuration Parameters\", json.dumps(conf))\n",
    "out_dir = f\"{data_dir}/{args.run_name}/models/\"\n",
    "\n",
    "best_epoch, best_iou = None, 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    loss_d = {}\n",
    "    loss_d[\"train\"], metrics_train = tr.train_epoch(loaders[\"train\"], frame, conf.metrics_opts)\n",
    "    tr.log_metrics(writer, metrics_train, loss_d[\"train\"], epoch, \"train\", mask_names=conf.log_opts.mask_names)\n",
    "    loss_d[\"val\"], metrics_val = tr.validate(loaders[\"val\"], frame, conf.metrics_opts)\n",
    "    tr.log_metrics(writer, metrics_val, loss_d[\"val\"], epoch, \"val\", mask_names=conf.log_opts.mask_names)\n",
    "\n",
    "    # save model\n",
    "    writer.add_scalars(\"Loss\", loss_d, epoch)\n",
    "    if (epoch + 1) % args.save_every == 0:\n",
    "        frame.save(out_dir, epoch)\n",
    "        tr.log_images(writer, frame, next(iter(loaders[\"train\"])), epoch)\n",
    "        tr.log_images(writer, frame, next(iter(loaders[\"val\"])), epoch, \"val\")\n",
    "\n",
    "    if best_iou <= metrics_val['IoU'][0]:\n",
    "        best_iou  = metrics_val['IoU'][0]\n",
    "        best_epoch = epoch\n",
    "        frame.save(out_dir, \"best\")\n",
    "\n",
    "    print(f\"{epoch}/{args.epochs} | train loss: {loss_d['train']} | val loss: {loss_d['val']}\")\n",
    "\n",
    "frame.save(out_dir, \"final\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Dict(yaml.safe_load(open(\"conf/train.yaml\", \"r\")))\n",
    "device = torch.device(args.device)\n",
    "\n",
    "model_dir = f\"{data_dir}/demo/models/model_best.pt\"\n",
    "\n",
    "outchannels = conf.model_opts.args.outchannels\n",
    "\n",
    "if outchannels > 1:\n",
    "    loss_weight = [1 for _ in range(outchannels)]\n",
    "    loss_weight[-1] = 0 # background\n",
    "    loss_fn = diceloss(act=torch.nn.Softmax(dim=1), w=loss_weight,\n",
    "                               outchannels=outchannels)\n",
    "else:\n",
    "    loss_fn = diceloss()\n",
    "\n",
    "frame = Framework(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "unet = frame.model\n",
    "unet.load_state_dict(torch.load(model_dir))\n",
    "unet = unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,15,512,512).to(device)\n",
    "y = unet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "mod = unet\n",
    "summary(mod, (15, 512, 512), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "make_dot(y, params=dict(list(unet.named_parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glacier_mapping.data.data import fetch_loaders\n",
    "from glacier_mapping.models.frame import Framework\n",
    "import glacier_mapping.train as tr\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from glacier_mapping.models.metrics import diceloss\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf = Dict(yaml.safe_load(open(\"conf/train.yaml\", \"r\")))\n",
    "device = torch.device(args.device)\n",
    "\n",
    "model_dir = f\"{data_dir}/demo/models/model_best.pt\"\n",
    "\n",
    "outchannels = conf.model_opts.args.outchannels\n",
    "\n",
    "if outchannels > 1:\n",
    "    loss_weight = [1 for _ in range(outchannels)]\n",
    "    loss_weight[-1] = 0 # background\n",
    "    loss_fn = diceloss(act=torch.nn.Softmax(dim=1), w=loss_weight,\n",
    "                               outchannels=outchannels)\n",
    "else:\n",
    "    loss_fn = diceloss()\n",
    "\n",
    "frame = Framework(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "unet = frame.model\n",
    "unet.load_state_dict(torch.load(model_dir))\n",
    "unet = unet.to(device)\n",
    "\n",
    "slices_dir = f\"{process_dir}/test/*img*\"\n",
    "pred_dir = f\"{process_dir}/preds/\"\n",
    "pred_dir2 = f\"{process_dir}/preds2/\"\n",
    "    \n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)\n",
    "\n",
    "slices = glob.glob(slices_dir)\n",
    "\n",
    "total_inference_time = 0\n",
    "for s in slices:\n",
    "    filename = s.split(\"/\")[-1].replace(\"npy\",\"png\")\n",
    "    filename2 = s.split(\"/\")[-1]\n",
    "    inp_np = np.load(s)\n",
    "    start = time.time()\n",
    "    nan_mask = np.isnan(inp_np[:,:,:9]).any(axis=2)\n",
    "    inp_tensor = torch.from_numpy(np.expand_dims(np.transpose(inp_np, (2,0,1)), axis=0))\n",
    "    inp_tensor = inp_tensor.to(device)\n",
    "    output = unet(inp_tensor)\n",
    "    output_np = output.detach().cpu().numpy()\n",
    "    output_np = np.transpose(output_np[0], (1,2,0))\n",
    "    output_np = np.argmax(output_np, axis=2)\n",
    "    output_np[nan_mask] = 3\n",
    "    total_inference_time += (time.time() - start)\n",
    "    plt.imsave(f\"{pred_dir}{filename}\", output_np, vmin=0, vmax=3)\n",
    "    np.save(f\"{pred_dir2}{filename2}\", output_np)\n",
    "    \n",
    "print(f\"Total inference time: {total_inference_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii as ba\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir datadrive/glaciers/demo/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and use the metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, f1_score, jaccard_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import rasterio\n",
    "import os\n",
    "\n",
    "y_true = list()\n",
    "y_pred_tmp = list()\n",
    "y_pred_tmp1 = list()\n",
    "y_pred_tmp2 = list()\n",
    "y_pred_tmp3 = list()\n",
    "\n",
    "pred_png = list()\n",
    "\n",
    "\n",
    "test_path = \"/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed\"\n",
    "true = 'masks'\n",
    "pred = 'preds2/Unet'\n",
    "\n",
    "names_images = sorted(os.listdir(os.path.join(test_path,true)))\n",
    "pred_png = sorted(os.listdir(os.path.join(test_path,pred)))\n",
    "\n",
    "\n",
    "for image in names_images:\n",
    "    path = os.path.join(test_path,true,image)\n",
    "    img_open = np.load(path)\n",
    "    y_true.append(img_open)\n",
    "\n",
    "for prediction in pred_png:\n",
    "    path = os.path.join(test_path,pred,prediction)\n",
    "    img_open = np.load(path)\n",
    "    y_pred_tmp.append(img_open)\n",
    "\n",
    "\n",
    "y_true = np.asarray(y_true)\n",
    "y_pred = np.asarray(y_pred_tmp)\n",
    "\n",
    "y_true_tmp = np.zeros_like(y_pred)\n",
    "y_true_tmp[y_true[:,:,:,0]==1] = 0\n",
    "y_true_tmp[y_true[:,:,:,1]==1] = 1\n",
    "y_true_tmp[y_true[:,:,:,2]==1] = 2\n",
    "\n",
    "y_true = y_true_tmp\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "\n",
    "y_true = y_true.ravel()\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "f1_score_teste = f1_score(y_true, y_pred,average='macro')\n",
    "print(\"F1-score: \",f1_score_teste)\n",
    "\n",
    "accuracy_score_teste = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy: \",accuracy_score_teste)\n",
    "\n",
    "all_metrics = precision_recall_fscore_support(y_true, y_pred,average=\"macro\")\n",
    "print(\"Precision, recall and fscore: \", all_metrics)\n",
    "\n",
    "iou_score_test = jaccard_score(y_true, y_pred, average=None)\n",
    "print(\"IoU: \",iou_score_test)\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix: \")\n",
    "print(cf)\n",
    "\n",
    "\n",
    "fbeta = fbeta_score(y_true, y_pred, average='macro', beta=0.01)\n",
    "print(\"Fbeta: \", fbeta)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize percentages in confusion matrix (the sum of each row is equal to 100%)\n",
    "mat = list()\n",
    "mat.append(cf[0]/3951515)\n",
    "mat.append(cf[1]/478519)\n",
    "mat.append(cf[2]/12871470)\n",
    "mat = np.array(mat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=mat, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/qubvel/segmentation_models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Dict({\n",
    "    \"batch_size\": 16,\n",
    "    \"run_name\": \"demo\", \n",
    "    \"epochs\": 200,\n",
    "    \"save_every\": 50,\n",
    "    \"loss_type\": \"dice\",\n",
    "    \"device\": 'cuda:0'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glacier_mapping.data.data import fetch_loaders\n",
    "from glacier_mapping.models.frame import Framework\n",
    "import glacier_mapping.train as tr\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from glacier_mapping.models.metrics import diceloss\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "\n",
    "conf = Dict(yaml.safe_load(open(\"conf/train_fpn.yaml\", \"r\")))\n",
    "conf.model_opts.name = 'FPN'\n",
    "train_folder = \"train\"\n",
    "dev_folder = \"dev\"\n",
    "loaders = fetch_loaders(process_dir, args.batch_size, train_folder, dev_folder)\n",
    "device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Frame to Combine Model with Optimizer\n",
    "\n",
    "This wraps the model and optimizer objects needed in training, so that each\n",
    "training step can be concisely called with a single method (optimize).\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from glacier_mapping.models.metrics import *\n",
    "from glacier_mapping.models.reg import *\n",
    "from segmentation_models_pytorch.decoders.fpn.model import *\n",
    "from segmentation_models_pytorch.decoders.manet.model import *\n",
    "\n",
    "\n",
    "class Framework2:\n",
    "    \"\"\"\n",
    "    Class to Wrap all the Training Steps\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loss_fn=None, model_opts=None, optimizer_opts=None,\n",
    "                 reg_opts=None, device=None):\n",
    "        \"\"\"\n",
    "        Set Class Attrributes\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        self.multi_class = True if model_opts.args.classes > 1 else False\n",
    "        self.num_classes = model_opts.args.classes\n",
    "        if loss_fn is None:\n",
    "            if self.multi_class:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            else:\n",
    "                loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.loss_fn = loss_fn.to(self.device)\n",
    "        if model_opts.name in [\"FPN\",\"MAnet\"]:\n",
    "            model_def = globals()[model_opts.name]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model name\")\n",
    "        print(model_def)\n",
    "        self.model = model_def(**model_opts.args).to(self.device)\n",
    "        optimizer_def = getattr(torch.optim, optimizer_opts.name)\n",
    "        self.optimizer = optimizer_def(self.model.parameters(), **optimizer_opts.args)\n",
    "        self.lrscheduler = ReduceLROnPlateau(self.optimizer, \"min\",\n",
    "                                             verbose=True, patience=10,\n",
    "                                             min_lr=1e-6)\n",
    "        self.reg_opts = reg_opts\n",
    "\n",
    "\n",
    "    def optimize(self, x, y):\n",
    "        \"\"\"\n",
    "        Take a single gradient step\n",
    "\n",
    "        Args:\n",
    "            X: raw training data\n",
    "            y: labels\n",
    "        Return:\n",
    "            optimization\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 3, 1, 2).to(self.device)\n",
    "        y = y.permute(0, 3, 1, 2).to(self.device)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.calc_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return y_hat.permute(0, 2, 3, 1), loss.item()\n",
    "\n",
    "    def val_operations(self, val_loss):\n",
    "        \"\"\"\n",
    "        Update the LR Scheduler\n",
    "        \"\"\"\n",
    "        self.lrscheduler.step(val_loss)\n",
    "\n",
    "    def save(self, out_dir, epoch):\n",
    "        \"\"\"\n",
    "        Save a model checkpoint\n",
    "        \"\"\"\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "\n",
    "        model_path = Path(out_dir, f\"model_{epoch}.pt\")\n",
    "        optim_path = Path(out_dir, f\"optim_{epoch}.pt\")\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        torch.save(self.optimizer.state_dict(), optim_path)\n",
    "\n",
    "    def infer(self, x):\n",
    "        \"\"\" Make a prediction for a given x\n",
    "\n",
    "        Args:\n",
    "            x: input x\n",
    "\n",
    "        Return:\n",
    "            Prediction\n",
    "\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 3, 1, 2).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            return self.model(x).permute(0, 2, 3, 1)\n",
    "\n",
    "    def segment(self, y_hat):\n",
    "        \"\"\"Predict a class given logits\n",
    "\n",
    "        Args:\n",
    "            y_hat: logits output\n",
    "\n",
    "        Return:\n",
    "            Probability of class in case of binary classification\n",
    "            or one-hot tensor in case of multi class\"\"\"\n",
    "        if self.multi_class:\n",
    "            y_hat = torch.argmax(y_hat, axis=3)\n",
    "            y_hat = torch.nn.functional.one_hot(y_hat, num_classes=self.num_classes)\n",
    "        else:\n",
    "            y_hat = torch.sigmoid(y_hat)\n",
    "        return y_hat\n",
    "\n",
    "    def act(self, logits):\n",
    "        \"\"\"Applies activation function based on the model\n",
    "        Args:\n",
    "            y_hat: logits output\n",
    "        Returns:\n",
    "            logits after applying activation function\"\"\"\n",
    "\n",
    "        if self.multi_class:\n",
    "            y_hat = torch.nn.Softmax(3)(logits)\n",
    "        else:\n",
    "            y_hat = torch.sigmoid(logits)\n",
    "        return y_hat\n",
    "\n",
    "    def calc_loss(self, y_hat, y):\n",
    "        \"\"\" Compute loss given a prediction\n",
    "\n",
    "        Args:\n",
    "            y_hat: Prediction\n",
    "            y: Label\n",
    "\n",
    "        Return:\n",
    "            Loss values\n",
    "\n",
    "        \"\"\"\n",
    "        y_hat = y_hat.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        if self.multi_class:\n",
    "            y = torch.argmax(y, dim=1)\n",
    "            y = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        for reg_type in self.reg_opts.keys():\n",
    "            reg_fun = globals()[reg_type]\n",
    "            penalty = reg_fun(\n",
    "                self.model.parameters(),\n",
    "                self.reg_opts[reg_type],\n",
    "                self.device\n",
    "            )\n",
    "            loss += penalty\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def metrics(self, y_hat, y, metrics_opts):\n",
    "        \"\"\" Loop over metrics in train.yaml\n",
    "\n",
    "        Args:\n",
    "            y_hat: Predictions\n",
    "            y: Labels\n",
    "            metrics_opts: Metrics specified in the train.yaml\n",
    "\n",
    "        Return:\n",
    "            results\n",
    "\n",
    "        \"\"\"\n",
    "        y_hat = y_hat.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        results = {}\n",
    "        for k, metric in metrics_opts.items():\n",
    "            if \"threshold\" in metric.keys():\n",
    "                y_hat = y_hat > metric[\"threshold\"]\n",
    "\n",
    "            metric_fun = globals()[k]\n",
    "            results[k] = metric_fun(y_hat, y)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = None\n",
    "outchannels = conf.model_opts.args.classes\n",
    "if args.loss_type == \"dice\":\n",
    "    loss_fn = diceloss(\n",
    "        act=torch.nn.Softmax(dim=1), \n",
    "        w=[0.6, 0.9, 0.2], # clean ice, debris, background\n",
    "        outchannels=outchannels, \n",
    "        label_smoothing=0.2\n",
    "    )\n",
    "    \n",
    "frame = Framework2(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "# encoder name\n",
    "enc_name = conf.model_opts.args.encoder_name\n",
    "\n",
    "# Setup logging\n",
    "writer = SummaryWriter(f\"{data_dir}/{args.run_name}/FPN/{enc_name}/logs/\")\n",
    "writer.add_text(\"Arguments\", json.dumps(vars(args)))\n",
    "writer.add_text(\"Configuration Parameters\", json.dumps(conf))\n",
    "out_dir = f\"{data_dir}/{args.run_name}/models/FPN/{enc_name}/\"\n",
    "\n",
    "best_epoch, best_iou = None, 0\n",
    "for epoch in range(args.epochs):\n",
    "  loss_d = {}\n",
    "  loss_d[\"train\"], metrics_train = tr.train_epoch(loaders[\"train\"], frame, conf.metrics_opts)\n",
    "  tr.log_metrics(writer, metrics_train, loss_d[\"train\"], epoch, \"train\", mask_names=conf.log_opts.mask_names)\n",
    "  loss_d[\"val\"], metrics_val = tr.validate(loaders[\"val\"], frame, conf.metrics_opts)\n",
    "  tr.log_metrics(writer, metrics_val, loss_d[\"val\"], epoch, \"val\", mask_names=conf.log_opts.mask_names)\n",
    "\n",
    "  # save model\n",
    "  writer.add_scalars(\"Loss\", loss_d, epoch)\n",
    "  if (epoch + 1) % args.save_every == 0:\n",
    "      frame.save(out_dir, epoch)\n",
    "      tr.log_images(writer, frame, next(iter(loaders[\"train\"])), epoch)\n",
    "      tr.log_images(writer, frame, next(iter(loaders[\"val\"])), epoch, \"val\")\n",
    "\n",
    "  if best_iou <= metrics_val['IoU'][0]:\n",
    "      best_iou  = metrics_val['IoU'][0]\n",
    "      best_epoch = epoch\n",
    "      frame.save(out_dir, \"best\")\n",
    "\n",
    "  print(f\"{epoch}/{args.epochs} | train loss: {loss_d['train']} | val loss: {loss_d['val']}\")\n",
    "\n",
    "frame.save(out_dir, \"final\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glacier_mapping.data.data import fetch_loaders\n",
    "import glacier_mapping.train as tr\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from glacier_mapping.models.metrics import diceloss\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Dict(yaml.safe_load(open(\"conf/train_fpn.yaml\", \"r\")))\n",
    "conf.model_opts.name = 'FPN'\n",
    "device = torch.device(args.device)\n",
    "\n",
    "model_dir = f\"{data_dir}/demo/models/FPN/vgg19/model_best.pt\"\n",
    "\n",
    "outchannels = conf.model_opts.args.classes\n",
    "\n",
    "if outchannels > 1:\n",
    "    loss_weight = [1 for _ in range(outchannels)]\n",
    "    loss_weight[-1] = 0 # background\n",
    "    loss_fn = diceloss(act=torch.nn.Softmax(dim=1), w=loss_weight,\n",
    "                               outchannels=outchannels)\n",
    "else:\n",
    "    loss_fn = diceloss()\n",
    "\n",
    "frame = Framework2(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "fpn = frame.model\n",
    "fpn.load_state_dict(torch.load(model_dir))#, map_location=torch.device('cpu')\n",
    "fpn = fpn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f\"{data_dir}/{args.run_name}/logs/model_plot/fpn/\")\n",
    "x = torch.randn(16,15,512,512).to(device)\n",
    "writer.add_graph(fpn, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir datadrive/glaciers/demo/logs/model_plot/fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir datadrive/glaciers/demo/FPN/vgg19/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_dir = f\"{process_dir}/test/*img*\"\n",
    "pred_dir = f\"{process_dir}/preds/FPN/\"\n",
    "pred_dir2 = f\"{process_dir}/preds2/FPN/\"\n",
    "    \n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)\n",
    "\n",
    "slices = glob.glob(slices_dir)\n",
    "\n",
    "total_inference_time = 0\n",
    "for s in slices:\n",
    "    filename = s.split(\"/\")[-1].replace(\"npy\",\"png\")\n",
    "    filename2 = s.split(\"/\")[-1]\n",
    "    inp_np = np.load(s)\n",
    "    start = time.time()\n",
    "    nan_mask = np.isnan(inp_np[:,:,:9]).any(axis=2)\n",
    "    inp_tensor = torch.from_numpy(np.expand_dims(np.transpose(inp_np, (2,0,1)), axis=0))\n",
    "    inp_tensor = inp_tensor.to(device)\n",
    "    output = fpn(inp_tensor)\n",
    "    output_np = output.detach().cpu().numpy()\n",
    "    output_np = np.transpose(output_np[0], (1,2,0))\n",
    "    output_np = np.argmax(output_np, axis=2)\n",
    "    output_np[nan_mask] = 3\n",
    "    total_inference_time += (time.time() - start)\n",
    "    plt.imsave(f\"{pred_dir}{filename}\", output_np, vmin=0, vmax=3)\n",
    "    np.save(f\"{pred_dir2}{filename2}\", output_np)\n",
    "print(f\"Total inference time: {total_inference_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, f1_score, multilabel_confusion_matrix, ConfusionMatrixDisplay, jaccard_score\n",
    "import rasterio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and use the metrics\n",
    "y_true = list()\n",
    "y_pred_tmp = list()\n",
    "y_pred_tmp1 = list()\n",
    "y_pred_tmp2 = list()\n",
    "y_pred_tmp3 = list()\n",
    "\n",
    "pred_png = list()\n",
    "\n",
    "\n",
    "test_path = \"/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed\"\n",
    "true = 'masks'\n",
    "pred = 'preds2/FPN'\n",
    "\n",
    "names_images = sorted(os.listdir(os.path.join(test_path,true)))\n",
    "pred_png = sorted(os.listdir(os.path.join(test_path,pred)))\n",
    "\n",
    "for image in names_images:\n",
    "    path = os.path.join(test_path,true,image)\n",
    "    img_open = np.load(path)\n",
    "    y_true.append(img_open)\n",
    "\n",
    "\n",
    "for prediction in pred_png:\n",
    "    path = os.path.join(test_path,pred,prediction)\n",
    "    img_open = np.load(path)\n",
    "    y_pred_tmp.append(img_open)\n",
    "\n",
    "y_true = np.asarray(y_true)\n",
    "y_pred = np.asarray(y_pred_tmp)\n",
    "\n",
    "y_true_tmp = np.zeros_like(y_pred)\n",
    "y_true_tmp[y_true[:,:,:,0]==1] = 0\n",
    "y_true_tmp[y_true[:,:,:,1]==1] = 1\n",
    "y_true_tmp[y_true[:,:,:,2]==1] = 2\n",
    "\n",
    "y_true = y_true_tmp\n",
    "\n",
    "\n",
    "y_true = y_true.ravel()\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "f1_score_teste = f1_score(y_true, y_pred,average='macro')\n",
    "print(\"F1-score: \",f1_score_teste)\n",
    "\n",
    "accuracy_score_teste = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy: \",accuracy_score_teste)\n",
    "\n",
    "all_metrics = precision_recall_fscore_support(y_true, y_pred,average=\"macro\")\n",
    "print(\"Precision, recall and fscore: \", all_metrics)\n",
    "\n",
    "iou_score_test = jaccard_score(y_true, y_pred, average=None)\n",
    "print(\"IoU: \",iou_score_test)\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix: \")\n",
    "print(cf)\n",
    "\n",
    "\n",
    "fbeta = fbeta_score(y_true, y_pred, average='macro', beta=0.01)\n",
    "print(\"Fbeta: \", fbeta)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize percentages in confusion matrix (the sum of each row is equal to 100%)\n",
    "mat = list()\n",
    "mat.append(cf[0]/3951515)\n",
    "mat.append(cf[1]/478519)\n",
    "mat.append(cf[2]/12871470)\n",
    "mat = np.array(mat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=mat, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glacier_mapping.data.data import fetch_loaders\n",
    "import glacier_mapping.train as tr\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from glacier_mapping.models.metrics import diceloss\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "\n",
    "conf = Dict(yaml.safe_load(open(\"conf/train_manet.yaml\", \"r\")))\n",
    "conf.model_opts.name = 'MAnet'\n",
    "train_folder = \"train\"\n",
    "dev_folder = \"dev\"\n",
    "loaders = fetch_loaders(process_dir, args.batch_size, train_folder, dev_folder)\n",
    "device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = None\n",
    "outchannels = conf.model_opts.args.classes\n",
    "if args.loss_type == \"dice\":\n",
    "    loss_fn = diceloss(\n",
    "        act=torch.nn.Softmax(dim=1), \n",
    "        w=[0.6, 0.9, 0.2], # clean ice, debris, background\n",
    "        outchannels=outchannels, \n",
    "        label_smoothing=0.2\n",
    "    )\n",
    "    \n",
    "frame = Framework2(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "# encoder name\n",
    "enc_name = conf.model_opts.args.encoder_name\n",
    "\n",
    "# Setup logging\n",
    "writer = SummaryWriter(f\"{data_dir}/{args.run_name}/MANet/{enc_name}/logs/\")\n",
    "writer.add_text(\"Arguments\", json.dumps(vars(args)))\n",
    "writer.add_text(\"Configuration Parameters\", json.dumps(conf))\n",
    "out_dir = f\"{data_dir}/{args.run_name}/models/MANet/{enc_name}/\"\n",
    "\n",
    "best_epoch, best_iou = None, 0\n",
    "for epoch in range(args.epochs):\n",
    "  loss_d = {}\n",
    "  loss_d[\"train\"], metrics_train = tr.train_epoch(loaders[\"train\"], frame, conf.metrics_opts)\n",
    "  tr.log_metrics(writer, metrics_train, loss_d[\"train\"], epoch, \"train\", mask_names=conf.log_opts.mask_names)\n",
    "  loss_d[\"val\"], metrics_val = tr.validate(loaders[\"val\"], frame, conf.metrics_opts)\n",
    "  tr.log_metrics(writer, metrics_val, loss_d[\"val\"], epoch, \"val\", mask_names=conf.log_opts.mask_names)\n",
    "\n",
    "  # save model\n",
    "  writer.add_scalars(\"Loss\", loss_d, epoch)\n",
    "  if (epoch + 1) % args.save_every == 0:\n",
    "      frame.save(out_dir, epoch)\n",
    "      tr.log_images(writer, frame, next(iter(loaders[\"train\"])), epoch)\n",
    "      tr.log_images(writer, frame, next(iter(loaders[\"val\"])), epoch, \"val\")\n",
    "\n",
    "  if best_iou <= metrics_val['IoU'][0]:\n",
    "      best_iou  = metrics_val['IoU'][0]\n",
    "      best_epoch = epoch\n",
    "      frame.save(out_dir, \"best\")\n",
    "\n",
    "  print(f\"{epoch}/{args.epochs} | train loss: {loss_d['train']} | val loss: {loss_d['val']}\")\n",
    "\n",
    "frame.save(out_dir, \"final\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glacier_mapping.data.data import fetch_loaders\n",
    "from glacier_mapping.models.frame import Framework\n",
    "import glacier_mapping.train as tr\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from glacier_mapping.models.metrics import diceloss\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Dict(yaml.safe_load(open(\"conf/train_manet.yaml\", \"r\")))\n",
    "conf.model_opts.name = 'MAnet'\n",
    "device = torch.device(args.device)\n",
    "\n",
    "model_dir = f\"{data_dir}/demo/models/MANet/vgg16/model_best.pt\"\n",
    "\n",
    "outchannels = conf.model_opts.args.classes\n",
    "\n",
    "if outchannels > 1:\n",
    "    loss_weight = [1 for _ in range(outchannels)]\n",
    "    loss_weight[-1] = 0 # background\n",
    "    loss_fn = diceloss(act=torch.nn.Softmax(dim=1), w=loss_weight,\n",
    "                               outchannels=outchannels)\n",
    "else:\n",
    "    loss_fn = diceloss()\n",
    "\n",
    "frame = Framework2(\n",
    "    model_opts=conf.model_opts,\n",
    "    optimizer_opts=conf.optim_opts,\n",
    "    reg_opts=conf.reg_opts,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "manet = frame.model\n",
    "manet.load_state_dict(torch.load(model_dir))#, map_location=torch.device('cpu')\n",
    "manet = manet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f\"{data_dir}/{args.run_name}/logs/model_plot/manet/\")\n",
    "x = torch.randn(16,15,512,512).to(device)\n",
    "writer.add_graph(manet, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir datadrive/glaciers/demo/logs/model_plot/manet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir datadrive/glaciers/demo/MANet/vgg16/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_dir = f\"{process_dir}/test/*img*\"\n",
    "pred_dir = f\"{process_dir}/preds/MANet/vgg16/\"\n",
    "pred_dir2 = f\"{process_dir}/preds2/MANet/vgg16/\"\n",
    "    \n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)\n",
    "\n",
    "slices = glob.glob(slices_dir)\n",
    "\n",
    "total_inference_time = 0\n",
    "for s in slices:\n",
    "    filename = s.split(\"/\")[-1].replace(\"npy\",\"png\")\n",
    "    filename2 = s.split(\"/\")[-1]\n",
    "    inp_np = np.load(s)\n",
    "    start = time.time()\n",
    "    nan_mask = np.isnan(inp_np[:,:,:9]).any(axis=2)\n",
    "    inp_tensor = torch.from_numpy(np.expand_dims(np.transpose(inp_np, (2,0,1)), axis=0))\n",
    "    inp_tensor = inp_tensor.to(device)\n",
    "    output = manet(inp_tensor)\n",
    "    output_np = output.detach().cpu().numpy()\n",
    "    output_np = np.transpose(output_np[0], (1,2,0))\n",
    "    output_np = np.argmax(output_np, axis=2)\n",
    "    output_np[nan_mask] = 3\n",
    "    total_inference_time += (time.time() - start)\n",
    "    plt.imsave(f\"{pred_dir}{filename}\", output_np, vmin=0, vmax=3)\n",
    "    np.save(f\"{pred_dir2}{filename2}\", output_np)\n",
    "print(f\"Total inference time: {total_inference_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, f1_score, jaccard_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import rasterio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and use the metrics\n",
    "y_true = list()\n",
    "y_pred_tmp = list()\n",
    "y_pred_tmp1 = list()\n",
    "y_pred_tmp2 = list()\n",
    "y_pred_tmp3 = list()\n",
    "\n",
    "pred_png = list()\n",
    "\n",
    "\n",
    "test_path = \"/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed\"\n",
    "true = 'masks'\n",
    "pred = 'preds2/MANet/vgg16'\n",
    "\n",
    "names_images = sorted(os.listdir(os.path.join(test_path,true)))\n",
    "pred_png = sorted(os.listdir(os.path.join(test_path,pred)))\n",
    "\n",
    "for image in names_images:\n",
    "    path = os.path.join(test_path,true,image)\n",
    "    img_open = np.load(path)\n",
    "    y_true.append(img_open)\n",
    "\n",
    "for prediction in pred_png:\n",
    "    path = os.path.join(test_path,pred,prediction)\n",
    "    img_open = np.load(path)\n",
    "    y_pred_tmp.append(img_open)\n",
    "\n",
    "y_true = np.asarray(y_true)\n",
    "y_pred = np.asarray(y_pred_tmp)\n",
    "\n",
    "y_true_tmp = np.zeros_like(y_pred)\n",
    "y_true_tmp[y_true[:,:,:,0]==1] = 0\n",
    "y_true_tmp[y_true[:,:,:,1]==1] = 1\n",
    "y_true_tmp[y_true[:,:,:,2]==1] = 2\n",
    "\n",
    "y_true = y_true_tmp\n",
    "\n",
    "\n",
    "y_true = y_true.ravel()\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "f1_score_teste = f1_score(y_true, y_pred,average='macro')\n",
    "print(\"F1-score: \",f1_score_teste)\n",
    "\n",
    "accuracy_score_teste = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy: \",accuracy_score_teste)\n",
    "\n",
    "all_metrics = precision_recall_fscore_support(y_true, y_pred,average=\"macro\")\n",
    "print(\"Precision, recall and fscore: \", all_metrics)\n",
    "\n",
    "iou_score_test = jaccard_score(y_true, y_pred, average=None)\n",
    "print(\"IoU: \",iou_score_test)\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix: \")\n",
    "print(cf)\n",
    "\n",
    "\n",
    "fbeta = fbeta_score(y_true, y_pred, average='macro', beta=0.01)\n",
    "print(\"Fbeta: \", fbeta)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()\n",
    "mat = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize percentages in confusion matrix (the sum of each row is equal to 100%)\n",
    "mat.append(cf[0]/3951515)\n",
    "mat.append(cf[1]/478519)\n",
    "mat.append(cf[2]/12871470)\n",
    "mat = np.array(mat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=mat, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(loaders['train']))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size, h, w, _ = train_features.shape\n",
    "train_features = train_features.reshape(b_size*h*w, -1)\n",
    "train_labels = train_labels.reshape(b_size*h*w, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "for load in iter(loaders['train']):\n",
    "  train_features, train_labels = load\n",
    "  del load\n",
    "  print(train_features.shape)\n",
    "  b_size, h, w, _ = train_features.shape\n",
    "  train_features = train_features.reshape(b_size*h*w, -1)\n",
    "  train_labels = train_labels.reshape(b_size*h*w, -1)\n",
    "  clf.fit(train_features,train_labels)\n",
    "  del train_features\n",
    "  del train_labels\n",
    "#clf.save(out_dir, \"randomforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(train_features,train_labels)\n",
    "filename = '/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/random_forest.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/random_forest.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'Low-Gain TIR', 'High-Gain TIR', 'SWIR2', 'Panchromatic', 'Quality Bitmask', 'NDVI', 'NDSI', 'NDWI', 'Elevation', 'Slope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = loaded_model.feature_importances_.argsort()\n",
    "plt.barh(labels, loaded_model.feature_importances_)\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_dir = f\"{process_dir}/test/*img*\"\n",
    "pred_dir = f\"{process_dir}/preds/RandomForest/\"\n",
    "pred_dir2 = f\"{process_dir}/preds2/RandomForest/\"\n",
    "    \n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)\n",
    "\n",
    "if not os.path.exists(pred_dir2):\n",
    "    os.makedirs(pred_dir2)\n",
    "\n",
    "slices = glob.glob(slices_dir)\n",
    "\n",
    "total_inference_time = 0\n",
    "for s in slices:\n",
    "    filename = s.split(\"/\")[-1].replace(\"npy\",\"png\")\n",
    "    filename2 = s.split(\"/\")[-1]\n",
    "    inp_np = np.load(s)\n",
    "    input = inp_np.reshape(-1,15)\n",
    "    start = time.time()\n",
    "    y_pred = loaded_model.predict(input)\n",
    "    classification = y_pred.reshape(512,512,3)\n",
    "    total_inference_time += (time.time() - start)\n",
    "    plt.imsave(f\"{pred_dir}{filename}\", classification, vmin=0, vmax=3)\n",
    "    np.save(f\"{pred_dir2}{filename2}\", classification)\n",
    "print(f\"Total inference time: {total_inference_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification.shape)\n",
    "y_true_tmp = np.zeros_like(classification)\n",
    "y_true_tmp[classification[:,:,0]==1] = 0\n",
    "y_true_tmp[classification[:,:,1]==1] = 1\n",
    "y_true_tmp[classification[:,:,2]==1] = 2\n",
    "print(y_true_tmp.shape)\n",
    "plt.imshow(y_true_tmp[...,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, f1_score, multilabel_confusion_matrix, ConfusionMatrixDisplay, jaccard_score\n",
    "import rasterio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and use the metrics\n",
    "y_true = list()\n",
    "y_pred_tmp = list()\n",
    "y_pred_tmp1 = list()\n",
    "y_pred_tmp2 = list()\n",
    "y_pred_tmp3 = list()\n",
    "\n",
    "pred_png = list()\n",
    "\n",
    "\n",
    "test_path = \"/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed\"\n",
    "true = 'masks'\n",
    "pred = 'preds2/RandomForest'\n",
    "\n",
    "names_images = sorted(os.listdir(os.path.join(test_path,true)))\n",
    "pred_png = sorted(os.listdir(os.path.join(test_path,pred)))\n",
    "\n",
    "for image in names_images:\n",
    "    path = os.path.join(test_path,true,image)\n",
    "    img_open = np.load(path)\n",
    "    y_true.append(img_open)\n",
    "\n",
    "for prediction in pred_png:\n",
    "    path = os.path.join(test_path,pred,prediction)\n",
    "    img_open = np.load(path)\n",
    "    y_pred_tmp.append(img_open)\n",
    "\n",
    "y_true = np.asarray(y_true)\n",
    "y_pred = np.asarray(y_pred_tmp)\n",
    "\n",
    "y_true_tmp = np.zeros_like(y_pred)\n",
    "y_true_tmp[y_true[:,:,:,0]==1] = 0\n",
    "y_true_tmp[y_true[:,:,:,1]==1] = 1\n",
    "y_true_tmp[y_true[:,:,:,2]==1] = 2\n",
    "\n",
    "y_true = y_true_tmp[...,0]\n",
    "\n",
    "\n",
    "y_pred_tmp = np.zeros_like(y_pred)\n",
    "y_pred_tmp[y_pred[:,:,:,0]==1] = 0\n",
    "y_pred_tmp[y_pred[:,:,:,1]==1] = 1\n",
    "y_pred_tmp[y_pred[:,:,:,2]==1] = 2\n",
    "\n",
    "y_pred = y_pred_tmp[...,0]\n",
    "\n",
    "y_true = y_true.ravel()\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "f1_score_teste = f1_score(y_true, y_pred,average='macro')\n",
    "print(\"F1-score: \",f1_score_teste)\n",
    "\n",
    "accuracy_score_teste = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy: \",accuracy_score_teste)\n",
    "\n",
    "iou_score_test = jaccard_score(y_true, y_pred, average=None)\n",
    "print(\"IoU: \",iou_score_test)\n",
    "\n",
    "all_metrics = precision_recall_fscore_support(y_true, y_pred,average=\"macro\")\n",
    "print(\"Precision, recall and fscore: \", all_metrics)\n",
    "\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix: \")\n",
    "print(cf)\n",
    "\n",
    "\n",
    "fbeta = fbeta_score(y_true, y_pred, average='macro', beta=0.01)\n",
    "print(\"Fbeta: \", fbeta)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize percentages in confusion matrix (the sum of each row is equal to 100%)\n",
    "mat = list()\n",
    "mat.append(cf[0]/3951515)\n",
    "mat.append(cf[1]/478519)\n",
    "mat.append(cf[2]/12871470)\n",
    "mat = np.array(mat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=mat, display_labels=['Clean Ice', 'Debris', 'Background'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install earthpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import earthpy.plot as ep\n",
    "\n",
    "img_array = np.load('/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed/test/slice_8_img_132.npy')\n",
    "mask_array = np.load('/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed/test/slice_8_mask_132.npy')\n",
    "\n",
    "f, axarr = plt.subplots(3,5)\n",
    "axarr[0,0].imshow(img_array[...,0])\n",
    "axarr[0,1].imshow(img_array[...,1])\n",
    "axarr[0,2].imshow(img_array[...,2])\n",
    "axarr[0,3].imshow(img_array[...,3])\n",
    "axarr[0,4].imshow(img_array[...,4])\n",
    "\n",
    "axarr[1,0].imshow(img_array[...,5])\n",
    "axarr[1,1].imshow(img_array[...,6])\n",
    "axarr[1,2].imshow(img_array[...,7])\n",
    "axarr[1,3].imshow(img_array[...,8])\n",
    "axarr[1,4].imshow(img_array[...,9])\n",
    "\n",
    "axarr[2,0].imshow(img_array[...,10])\n",
    "axarr[2,1].imshow(img_array[...,11])\n",
    "axarr[2,2].imshow(img_array[...,12])\n",
    "axarr[2,3].imshow(img_array[...,13])\n",
    "axarr[2,4].imshow(img_array[...,14])\n",
    "\n",
    "\n",
    "f, bxarr = plt.subplots(1,3)\n",
    "bxarr[0].imshow(mask_array[...,0])\n",
    "bxarr[1].imshow(mask_array[...,1])\n",
    "bxarr[2].imshow(mask_array[...,2])\n",
    "\n",
    "mask = np.zeros_like(mask_array)\n",
    "mask[mask_array[:,:,0]==1] = 0\n",
    "mask[mask_array[:,:,1]==1] = 1\n",
    "mask[mask_array[:,:,2]==1] = 2\n",
    "print(mask.shape)\n",
    "f = plt.figure()\n",
    "plt.imshow(mask[...,0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image = np.dstack((img_array[...,2],img_array[...,1],img_array[...,0]))\n",
    "\n",
    "\n",
    "image2 = image.transpose(2,0,1)\n",
    "ep.plot_rgb(image2,\n",
    "            title=\"RGB Composite Image\",\n",
    "            stretch=True,\n",
    "            str_clip=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.load('/content/drive/MyDrive/Colab Notebooks/Tesi/glacier_mapping-master/datadrive/glaciers/processed/test/slice_2_img_109.npy')\n",
    "\n",
    "print('The shape of the image is ', img_arr.shape)\n",
    "\n",
    "image = np.dstack((img_arr[...,10],img_arr[...,11],img_arr[...,12]))\n",
    "print('The shape of the image (only indices) is ', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "# changing the index in the square brackets you can visualize the 15 bands\n",
    "plt.imshow(img_arr[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = img_arr.reshape(-1,15)\n",
    "print('The shape after reshaping of the image is ', x_img.shape)\n",
    "\n",
    "x_image = image.reshape(-1,3)\n",
    "print('The shape after reshaping of the image (only indices) is ', x_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(x_img)\n",
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_kwargs = {\n",
    "     \"init\": \"random\",\n",
    "     \"n_init\": 10,\n",
    "     \"max_iter\": 300,\n",
    "     \"random_state\": 42,\n",
    "}\n",
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(scaled_features)\n",
    "    sse.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(1, 11), sse)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(5)\n",
    "km.fit(x_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = km.predict(x_img).reshape(img_arr.shape[:-1])\n",
    "seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
